{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Custom Dataset ### CHANGE ME IF NEEDED ###\n",
    "print(os.getcwd())\n",
    "dataset_path = \"../../dataset/name_of_dataset\"\n",
    "images_path = dataset_path + \"/images\"\n",
    "labels_path = dataset_path + \"/Annotations\"\n",
    "\n",
    "# Label Map\n",
    "label_map = {1: 'name_of_object'}\n",
    "\n",
    "print(f\"Images: {images_path}\")\n",
    "print(f\"Labels: {labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db64ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_dataset(images_path, annotations_path, val_split, test_split, out_path):\n",
    "  \"\"\"Splits a directory of sorted images/annotations into training, validation, and test sets.\n",
    "\n",
    "  Args:\n",
    "    images_path: Path to the directory with your images (JPGs).\n",
    "    annotations_path: Path to a directory with your VOC XML annotation files,\n",
    "      with filenames corresponding to image filenames. This may be the same path\n",
    "      used for images_path.\n",
    "    val_split: Fraction of data to reserve for validation (float between 0 and 1).\n",
    "    test_split: Fraction of data to reserve for test (float between 0 and 1).\n",
    "  Returns:\n",
    "    The paths for the split images/annotations (train_dir, val_dir, test_dir)\n",
    "  \"\"\"\n",
    "  _, dirs, _ = next(os.walk(images_path))\n",
    "\n",
    "  train_dir = os.path.join(out_path, 'train')\n",
    "  val_dir = os.path.join(out_path, 'validation')\n",
    "  test_dir = os.path.join(out_path, 'test')\n",
    "\n",
    "  IMAGES_TRAIN_DIR = os.path.join(train_dir, 'images')\n",
    "  IMAGES_VAL_DIR = os.path.join(val_dir, 'images')\n",
    "  IMAGES_TEST_DIR = os.path.join(test_dir, 'images')\n",
    "  os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
    "  os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
    "  os.makedirs(IMAGES_TEST_DIR, exist_ok=True)\n",
    "\n",
    "  ANNOT_TRAIN_DIR = os.path.join(train_dir, 'annotations')\n",
    "  ANNOT_VAL_DIR = os.path.join(val_dir, 'annotations')\n",
    "  ANNOT_TEST_DIR = os.path.join(test_dir, 'annotations')\n",
    "  os.makedirs(ANNOT_TRAIN_DIR, exist_ok=True)\n",
    "  os.makedirs(ANNOT_VAL_DIR, exist_ok=True)\n",
    "  os.makedirs(ANNOT_TEST_DIR, exist_ok=True)\n",
    "\n",
    "  # Get all filenames for this dir, filtered by filetype\n",
    "  filenames = os.listdir(os.path.join(images_path))\n",
    "  filenames = [os.path.join(images_path, f) for f in filenames if (f.endswith('.jpg'))]\n",
    "  # Shuffle the files, deterministically\n",
    "  filenames.sort()\n",
    "  random.seed(42)\n",
    "  random.shuffle(filenames)\n",
    "  # Get exact number of images for validation and test; the rest is for training\n",
    "  val_count = int(len(filenames) * val_split)\n",
    "  test_count = int(len(filenames) * test_split)\n",
    "  for i, file in enumerate(filenames):\n",
    "    source_dir, filename = os.path.split(file)\n",
    "    annot_file = os.path.join(annotations_path, filename.replace(\"jpg\", \"xml\"))\n",
    "    if i < val_count:\n",
    "      shutil.copy(file, IMAGES_VAL_DIR)\n",
    "      shutil.copy(annot_file, ANNOT_VAL_DIR)\n",
    "    elif i < val_count + test_count:\n",
    "      shutil.copy(file, IMAGES_TEST_DIR)\n",
    "      shutil.copy(annot_file, ANNOT_TEST_DIR)\n",
    "    else:\n",
    "      shutil.copy(file, IMAGES_TRAIN_DIR)\n",
    "      shutil.copy(annot_file, ANNOT_TRAIN_DIR)\n",
    "  return (train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xml_declaration(annotations_dir):\n",
    "    for filename in os.listdir(annotations_dir):\n",
    "        if filename.endswith('.xml'):\n",
    "            path = os.path.join(annotations_dir, filename)\n",
    "            with open(path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            # Remove XML declaration if present\n",
    "            if content.startswith(b'<?xml'):\n",
    "                first_line_end = content.find(b'?>') + 2\n",
    "                content = content[first_line_end:].lstrip()\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0775b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, test\n",
    "train_dir, val_dir, test_dir = split_dataset(images_path, labels_path, val_split=0.2, test_split=0.2, out_path='split-dataset')\n",
    "\n",
    "# Clean data coming in from Label Studio\n",
    "clean_xml_declaration(os.path.join(train_dir, 'annotations'))\n",
    "clean_xml_declaration(os.path.join(val_dir, 'annotations'))\n",
    "clean_xml_declaration(os.path.join(test_dir, 'annotations'))\n",
    "\n",
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(train_dir, 'images'),\n",
    "    os.path.join(train_dir, 'annotations'), label_map=label_map)\n",
    "\n",
    "validation_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(val_dir, 'images'),\n",
    "    os.path.join(val_dir, 'annotations'), label_map=label_map)\n",
    "\n",
    "test_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(test_dir, 'images'),\n",
    "    os.path.join(test_dir, 'annotations'), label_map=label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c574c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a model\n",
    "spec = object_detector.EfficientDetLite0Spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b10a0ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = object_detector.create(train_data=train_data, \n",
    "                               model_spec=spec, \n",
    "                               validation_data=validation_data, \n",
    "                               epochs=50, \n",
    "                               batch_size=10, \n",
    "                               train_whole_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clean label names\n",
    "labels = [k for k in metrics if not k.startswith('AP_/')]\n",
    "values = [metrics[k] * 100 for k in labels]  # Convert to %\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(labels, values)\n",
    "plt.ylabel('Metric (%)')\n",
    "plt.title('Model Evaluation Metrics (COCO)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29064d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_FILENAME = 'name_of_model.tflite' # Rename output here!\n",
    "LABELS_FILENAME = 'objects.txt'\n",
    "\n",
    "model.export(export_dir='.', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n",
    "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tflite file using test data\n",
    "model.evaluate_tflite(TFLITE_FILENAME, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f41515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
